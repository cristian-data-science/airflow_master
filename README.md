# Airflow Patagonia Master

Este proyecto implementa un robusto pipeline de datos y procesos ETL (ExtracciÃ³n, TransformaciÃ³n, Carga) utilizando Apache Airflow, Docker y diversas herramientas de integraciÃ³n de datos. EstÃ¡ diseÃ±ado para manejar datos de mÃºltiples fuentes, incluyendo Shopify, D365 y OMS .

## ğŸš€ CaracterÃ­sticas

- Entorno Airflow containerizado usando Docker
- IntegraciÃ³n con fuentes de datos de Shopify, ERP y OMS
- Flujos de trabajo automatizados para procesamiento y carga de datos
- Optimizado para manejar datos de retail, datos de clientes e informaciÃ³n de pedidos
- Arquitectura escalable con DAGs separados para diferentes procesos de datos

## ğŸ› ï¸ Stack TecnolÃ³gico

- Apache Airflow 2.7.3
- Python 3.x
- PostgreSQL 13
- Docker y Docker Compose
- Conector de Snowflake
- pandas, pyarrow y otras bibliotecas de procesamiento de datos

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ .github/workflows/    # Flujos de trabajo de GitHub Actions
â”œâ”€â”€ dags/                 # Definiciones de DAGs de Airflow
â”‚   â”œâ”€â”€ config/           # Archivos de configuraciÃ³n
â”‚   â””â”€â”€ utils/            # Funciones de utilidad
â”œâ”€â”€ Dockerfile            # DefiniciÃ³n de imagen personalizada de Airflow
â”œâ”€â”€ docker-compose.yaml   # ConfiguraciÃ³n de Docker Compose
â”œâ”€â”€ .env                  # Variables de entorno (no rastreadas en git)
â”œâ”€â”€ .gitignore            # Reglas de ignorado de Git
â””â”€â”€ README.md             # Este archivo
```

## ğŸ”§ ConfiguraciÃ³n e InstalaciÃ³n

1. AsegÃºrate de tener Docker y Docker Compose instalados en tu sistema.
2. Clona este repositorio:
   ```
   git clone <url-del-repositorio>
   ```
3. Crea un archivo `.env` en el directorio raÃ­z con las variables de entorno necesarias.
4. Construye e inicia los servicios:
   ```
   docker-compose up -d --build
   ```

## ğŸ“Š Flujos de Datos

- **Datos de Shopify**: 
  - Procesamiento de datos de clientes (`shopify_customer_data.py`)
  - ExtracciÃ³n de datos de pedidos (`shopify_order_data.py`)
  - GestiÃ³n de variantes de productos (`shopify_product_variants.py`)

- **Datos de ERP**:
  - SincronizaciÃ³n de datos de clientes (`erp_customer_data.py`)
  - Procesamiento de datos de lÃ­neas de venta (`erp_salesline_data.py`, `erp_processed_salesline_data.py`)

- **Datos de OMS**:
  - GestiÃ³n de datos de pedidos (`oms_order_data.py`)
  - Seguimiento de datos de incidencias (`oms_incidence_data.py`)

- **IntegraciÃ³n con Klaviyo**:
  - Carga de datos de ventas minoristas (`klaviyo_retail_sales_loading.py`)

## ğŸ”„ CI/CD

El proyecto utiliza GitHub Actions para integraciÃ³n y despliegue continuos. Los flujos de trabajo se definen en el directorio `.github/workflows`.

## ğŸ³ ConfiguraciÃ³n de Docker

- Imagen personalizada de Airflow con dependencias adicionales
- Base de datos PostgreSQL para metadatos de Airflow
- Servicios separados para el servidor web de Airflow, el planificador y la inicializaciÃ³n

---

Para obtener informaciÃ³n mÃ¡s detallada sobre cada componente, consulta los archivos individuales y sus comentarios.
